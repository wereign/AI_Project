{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/wereign/juan-ai/1f5f9c8969024f81947e2e2cb897cf5a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comet_ml.init()\n",
    "experiment = comet_ml.Experiment(project_name='juan-ai',\n",
    "                                 auto_histogram_weight_logging=True,\n",
    "                                 auto_histogram_gradient_logging=True,\n",
    "                                 auto_histogram_activation_logging=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='../datasets/mnist_dataset',download=True,train=True,transform=transform)\n",
    "\n",
    "\n",
    "test_data = datasets.MNIST(root='../datasets/mnist_dataset',download=True,train=False,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../datasets/mnist_dataset\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ../datasets/mnist_dataset\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,batch_size=10,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down the working of convolutional layer\n",
    "\n",
    "- Conv2d Parameters\n",
    "1. In_Channels - Input Parameters\n",
    "2. Out_Channels - Out Parameters\n",
    "3. Kernel Size - Order of the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=3,stride=1)   # A 2 Dimensional Convolutional Layer\n",
    "conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3,stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (X_train,y_train) in enumerate(train_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  # Converting to four dimensions to make it resemble a batch\n",
    "x = X_train.view(1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "x = F.relu(conv1(x))\n",
    "\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "x = F.max_pool2d(x,2,2)\n",
    "print(x.shape) # Cutting the size in half , due to the pooling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "x = F.relu(conv2(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "x = F.max_pool2d(x,2,2)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feeding into a flat layer\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,16*5*5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2, 2)\n",
    "        X = X.view(-1, 5*5*16)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalNetwork(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "print(model)\n",
    "\n",
    "log_model(experiment, model, model_name=\"PyTorch_MNIST_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "6\n",
      "864\n",
      "16\n",
      "48000\n",
      "120\n",
      "10080\n",
      "84\n",
      "840\n",
      "10\n",
      "Total parameters: 60074\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for param in model.parameters():\n",
    "    total_parameters += param.numel()\n",
    "    print(param.numel()) # number of elements\n",
    "print(f'Total parameters: {total_parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"epochs\":30,\n",
    "    \"optimizer\":\"Adam\",\n",
    "    \"loss\":\"categorical_crossentropy\",\n",
    "    \"learning_rate\":0.001\n",
    "}\n",
    "\n",
    "experiment.log_parameters(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda:0\n",
      "epoch:  0  batch:  600 [  6000/60000]  loss: 0.03552599  accuracy:  98.650%\n",
      "epoch:  0  batch: 1200 [ 12000/60000]  loss: 0.00247115  accuracy:  98.525%\n",
      "epoch:  0  batch: 1800 [ 18000/60000]  loss: 0.00015366  accuracy:  98.617%\n",
      "epoch:  0  batch: 2400 [ 24000/60000]  loss: 0.13789721  accuracy:  98.621%\n",
      "epoch:  0  batch: 3000 [ 30000/60000]  loss: 0.01301519  accuracy:  98.533%\n",
      "epoch:  0  batch: 3600 [ 36000/60000]  loss: 0.00514564  accuracy:  98.544%\n",
      "epoch:  0  batch: 4200 [ 42000/60000]  loss: 0.00015343  accuracy:  98.536%\n",
      "epoch:  0  batch: 4800 [ 48000/60000]  loss: 0.03281840  accuracy:  98.558%\n",
      "epoch:  0  batch: 5400 [ 54000/60000]  loss: 0.00028812  accuracy:  98.559%\n",
      "epoch:  0  batch: 6000 [ 60000/60000]  loss: 0.00114125  accuracy:  98.537%\n",
      "epoch:  1  batch:  600 [  6000/60000]  loss: 0.00019616  accuracy:  98.900%\n",
      "epoch:  1  batch: 1200 [ 12000/60000]  loss: 0.00127282  accuracy:  98.975%\n",
      "epoch:  1  batch: 1800 [ 18000/60000]  loss: 0.00208672  accuracy:  98.906%\n",
      "epoch:  1  batch: 2400 [ 24000/60000]  loss: 0.00213370  accuracy:  98.842%\n",
      "epoch:  1  batch: 3000 [ 30000/60000]  loss: 0.00047534  accuracy:  98.870%\n",
      "epoch:  1  batch: 3600 [ 36000/60000]  loss: 0.32482502  accuracy:  98.878%\n",
      "epoch:  1  batch: 4200 [ 42000/60000]  loss: 0.00023705  accuracy:  98.931%\n",
      "epoch:  1  batch: 4800 [ 48000/60000]  loss: 0.00017482  accuracy:  98.900%\n",
      "epoch:  1  batch: 5400 [ 54000/60000]  loss: 0.02166892  accuracy:  98.907%\n",
      "epoch:  1  batch: 6000 [ 60000/60000]  loss: 0.00106269  accuracy:  98.888%\n",
      "epoch:  2  batch:  600 [  6000/60000]  loss: 0.00563412  accuracy:  99.367%\n",
      "epoch:  2  batch: 1200 [ 12000/60000]  loss: 0.00680894  accuracy:  99.308%\n",
      "epoch:  2  batch: 1800 [ 18000/60000]  loss: 0.11142403  accuracy:  99.206%\n",
      "epoch:  2  batch: 2400 [ 24000/60000]  loss: 0.01206702  accuracy:  99.112%\n",
      "epoch:  2  batch: 3000 [ 30000/60000]  loss: 0.04194245  accuracy:  99.067%\n",
      "epoch:  2  batch: 3600 [ 36000/60000]  loss: 0.00041366  accuracy:  99.064%\n",
      "epoch:  2  batch: 4200 [ 42000/60000]  loss: 0.00011387  accuracy:  99.090%\n",
      "epoch:  2  batch: 4800 [ 48000/60000]  loss: 0.04610158  accuracy:  99.106%\n",
      "epoch:  2  batch: 5400 [ 54000/60000]  loss: 0.00031037  accuracy:  99.076%\n",
      "epoch:  2  batch: 6000 [ 60000/60000]  loss: 0.00013760  accuracy:  99.085%\n",
      "epoch:  3  batch:  600 [  6000/60000]  loss: 0.00085776  accuracy:  99.100%\n",
      "epoch:  3  batch: 1200 [ 12000/60000]  loss: 0.34409609  accuracy:  99.267%\n",
      "epoch:  3  batch: 1800 [ 18000/60000]  loss: 0.00042835  accuracy:  99.311%\n",
      "epoch:  3  batch: 2400 [ 24000/60000]  loss: 0.00169246  accuracy:  99.312%\n",
      "epoch:  3  batch: 3000 [ 30000/60000]  loss: 0.15734108  accuracy:  99.287%\n",
      "epoch:  3  batch: 3600 [ 36000/60000]  loss: 0.00004400  accuracy:  99.253%\n",
      "epoch:  3  batch: 4200 [ 42000/60000]  loss: 0.00426404  accuracy:  99.262%\n",
      "epoch:  3  batch: 4800 [ 48000/60000]  loss: 0.01189887  accuracy:  99.244%\n",
      "epoch:  3  batch: 5400 [ 54000/60000]  loss: 0.00052806  accuracy:  99.224%\n",
      "epoch:  3  batch: 6000 [ 60000/60000]  loss: 0.00106728  accuracy:  99.220%\n",
      "epoch:  4  batch:  600 [  6000/60000]  loss: 0.00005644  accuracy:  99.433%\n",
      "epoch:  4  batch: 1200 [ 12000/60000]  loss: 0.00000783  accuracy:  99.392%\n",
      "epoch:  4  batch: 1800 [ 18000/60000]  loss: 0.00004829  accuracy:  99.344%\n",
      "epoch:  4  batch: 2400 [ 24000/60000]  loss: 0.00000799  accuracy:  99.317%\n",
      "epoch:  4  batch: 3000 [ 30000/60000]  loss: 0.00273624  accuracy:  99.317%\n",
      "epoch:  4  batch: 3600 [ 36000/60000]  loss: 0.00048035  accuracy:  99.325%\n",
      "epoch:  4  batch: 4200 [ 42000/60000]  loss: 0.00030704  accuracy:  99.338%\n",
      "epoch:  4  batch: 4800 [ 48000/60000]  loss: 0.00018510  accuracy:  99.306%\n",
      "epoch:  4  batch: 5400 [ 54000/60000]  loss: 0.00493465  accuracy:  99.302%\n",
      "epoch:  4  batch: 6000 [ 60000/60000]  loss: 0.00023978  accuracy:  99.302%\n",
      "\n",
      "Duration: 930 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device\",device)\n",
    "model = model.to(device=device)\n",
    "\n",
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "    \n",
    "    # Run the training batches\n",
    "    for b, (X_train, y_train) in enumerate(train_loader):\n",
    "\n",
    "        X_train,y_train = X_train.to(device),y_train.to(device)\n",
    "\n",
    "        b+=1\n",
    "        \n",
    "        # Apply the model\n",
    "        y_pred = model(X_train)  # we don't flatten X-train here\n",
    "        loss = criterion(y_pred, y_train)\n",
    " \n",
    "        # Tally the number of correct predictions\n",
    "        predicted = torch.max(y_pred.data, 1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        experiment.log_metrics({\"train_accuracy\": trn_corr.item()/(10*b), \"train_loss\": loss.item()}, epoch=i)\n",
    "        \n",
    "        # Print interim results\n",
    "        if b%600 == 0:\n",
    "            print(f'epoch: {i:2}  batch: {b:4} [{10*b:6}/60000]  loss: {loss.item():10.8f}  \\\n",
    "accuracy: {trn_corr.item()*100/(10*b):7.3f}%')\n",
    "        \n",
    "    train_losses.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "        \n",
    "    # Run the testing batches\n",
    "    with torch.no_grad():\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            # Apply the model\n",
    "            y_val = model(X_test)\n",
    "\n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_val.data, 1)[1] \n",
    "            tst_corr += (predicted == y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "    experiment.log_metrics({\"val_accuracy\": (tst_corr.item())/(10*b), \"val_loss\": loss.item()}, epoch=i)\n",
    "\n",
    "        \n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\viren\\Desktop\\AI_Project\\notebooks\\MNIST_CNN.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/viren/Desktop/AI_Project/notebooks/MNIST_CNN.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m loss_idx,item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_losses):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/viren/Desktop/AI_Project/notebooks/MNIST_CNN.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_losses[loss_idx] \u001b[39m=\u001b[39m item\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/viren/Desktop/AI_Project/notebooks/MNIST_CNN.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m loss_idx,item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_losses):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/viren/Desktop/AI_Project/notebooks/MNIST_CNN.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     test_losses[loss_idx] \u001b[39m=\u001b[39m item\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "for loss_idx,item in enumerate(train_losses):\n",
    "    train_losses[loss_idx] = item.cpu().detach().numpy().item()\n",
    "for loss_idx,item in enumerate(test_losses):\n",
    "    test_losses[loss_idx] = item.cpu().detach().numpy().item()\n",
    "plt.plot(train_losses,label='Train Loss')\n",
    "plt.plot(test_losses,label='Validation Loss')\n",
    "plt.title(\"LOSS AT EPOCH\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\viren\\Desktop\\AI_Project\\notebooks\\MNIST_CNN.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/viren/Desktop/AI_Project/notebooks/MNIST_CNN.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot([t\u001b[39m/\u001b[39;49m\u001b[39m600\u001b[39;49m \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m train_correct],label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTraining Accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/viren/Desktop/AI_Project/notebooks/MNIST_CNN.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot([t\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m test_correct], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation Accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/viren/Desktop/AI_Project/notebooks/MNIST_CNN.ipynb#X35sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mAccuracy at the end of the epoch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\matplotlib\\pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3570\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   3571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\n\u001b[0;32m   3572\u001b[0m     \u001b[39m*\u001b[39margs: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m ArrayLike \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3576\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3577\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3578\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   3579\u001b[0m         \u001b[39m*\u001b[39margs,\n\u001b[0;32m   3580\u001b[0m         scalex\u001b[39m=\u001b[39mscalex,\n\u001b[0;32m   3581\u001b[0m         scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   3582\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}),\n\u001b[0;32m   3583\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3584\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    304\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\matplotlib\\axes\\_base.py:491\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    489\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[0;32m    490\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 491\u001b[0m     x, y \u001b[39m=\u001b[39m index_of(xy[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    493\u001b[0m \u001b[39mif\u001b[39;00m axes\u001b[39m.\u001b[39mxaxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m     axes\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mupdate_units(x)\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\matplotlib\\cbook.py:1666\u001b[0m, in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1666\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(y)\n\u001b[0;32m   1667\u001b[0m \u001b[39mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1668\u001b[0m     \u001b[39m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\matplotlib\\cbook.py:1358\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[39m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m \u001b[39m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[0;32m   1354\u001b[0m \u001b[39m# Note this will strip unit information.\u001b[39;00m\n\u001b[0;32m   1355\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m         \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m         \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m-> 1358\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[0;32m   1359\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1360\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[0;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\viren\\miniconda3\\envs\\autogluon_env\\lib\\site-packages\\torch\\_tensor.py:1030\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m   1029\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1030\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m   1031\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcw0lEQVR4nO3db2zdVf3A8U/b0VsItEzn2m0WKyiiAhturBYkiKk2gUz3wDjBbHPhj+AkuEZlY7CK6DoRyKIrLkwQH6ibEDDGLUOsLgapWdjWBGSDwMBNYwsT184iLWu/vweG+qvrYLf0z077eiX3wY7n3O+5Hkbf3H8tyLIsCwCABBSO9QYAAI6VcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSkXe4/OEPf4h58+bF9OnTo6CgIH75y1++5Zpt27bFRz7ykcjlcvG+970v7r///iFsFQCY6PIOl66urpg5c2Y0NTUd0/wXXnghLrvssrjkkkuitbU1vvrVr8ZVV10VjzzySN6bBQAmtoK380sWCwoK4uGHH4758+cfdc6NN94Ymzdvjqeeeqp/7POf/3wcPHgwtm7dOtRLAwAT0KSRvkBLS0vU1tYOGKurq4uvfvWrR13T3d0d3d3d/X/u6+uLV155Jd75zndGQUHBSG0VABhGWZbFoUOHYvr06VFYODxvqx3xcGlra4vy8vIBY+Xl5dHZ2Rn//ve/48QTTzxiTWNjY9x6660jvTUAYBTs378/3v3udw/LfY14uAzFihUror6+vv/PHR0dcdppp8X+/fujtLR0DHcGAByrzs7OqKysjFNOOWXY7nPEw6WioiLa29sHjLW3t0dpaemgz7ZERORyucjlckeMl5aWChcASMxwvs1jxL/HpaamJpqbmweMPfroo1FTUzPSlwYAxpm8w+Vf//pXtLa2Rmtra0T85+POra2tsW/fvoj4z8s8ixYt6p9/7bXXxt69e+Mb3/hG7NmzJ+6+++74xS9+EcuWLRueRwAATBh5h8sTTzwR5513Xpx33nkREVFfXx/nnXderFq1KiIi/v73v/dHTETEe9/73ti8eXM8+uijMXPmzLjzzjvjRz/6UdTV1Q3TQwAAJoq39T0uo6WzszPKysqio6PDe1wAIBEj8fPb7yoCAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZQwqXpqamqKqqipKSkqiuro7t27e/6fy1a9fGBz7wgTjxxBOjsrIyli1bFq+99tqQNgwATFx5h8umTZuivr4+GhoaYufOnTFz5syoq6uLl156adD5P/vZz2L58uXR0NAQu3fvjnvvvTc2bdoUN91009vePAAwseQdLnfddVdcffXVsWTJkvjQhz4U69evj5NOOinuu+++Qec//vjjceGFF8YVV1wRVVVV8alPfSouv/zyt3yWBgDgf+UVLj09PbFjx46ora397x0UFkZtbW20tLQMuuaCCy6IHTt29IfK3r17Y8uWLXHppZce9Trd3d3R2dk54AYAMCmfyQcOHIje3t4oLy8fMF5eXh579uwZdM0VV1wRBw4ciI997GORZVkcPnw4rr322jd9qaixsTFuvfXWfLYGAEwAI/6pom3btsXq1avj7rvvjp07d8ZDDz0Umzdvjttuu+2oa1asWBEdHR39t/3794/0NgGABOT1jMuUKVOiqKgo2tvbB4y3t7dHRUXFoGtuueWWWLhwYVx11VUREXHOOedEV1dXXHPNNbFy5cooLDyynXK5XORyuXy2BgBMAHk941JcXByzZ8+O5ubm/rG+vr5obm6OmpqaQde8+uqrR8RJUVFRRERkWZbvfgGACSyvZ1wiIurr62Px4sUxZ86cmDt3bqxduza6urpiyZIlERGxaNGimDFjRjQ2NkZExLx58+Kuu+6K8847L6qrq+O5556LW265JebNm9cfMAAAxyLvcFmwYEG8/PLLsWrVqmhra4tZs2bF1q1b+9+wu2/fvgHPsNx8881RUFAQN998c/ztb3+Ld73rXTFv3rz4zne+M3yPAgCYEAqyBF6v6ezsjLKysujo6IjS0tKx3g4AcAxG4ue331UEACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhhQuTU1NUVVVFSUlJVFdXR3bt29/0/kHDx6MpUuXxrRp0yKXy8WZZ54ZW7ZsGdKGAYCJa1K+CzZt2hT19fWxfv36qK6ujrVr10ZdXV0888wzMXXq1CPm9/T0xCc/+cmYOnVqPPjggzFjxoz4y1/+Eqeeeupw7B8AmEAKsizL8llQXV0d559/fqxbty4iIvr6+qKysjKuv/76WL58+RHz169fH9/73vdiz549ccIJJwxpk52dnVFWVhYdHR1RWlo6pPsAAEbXSPz8zuulop6entixY0fU1tb+9w4KC6O2tjZaWloGXfOrX/0qampqYunSpVFeXh5nn312rF69Onp7e496ne7u7ujs7BxwAwDIK1wOHDgQvb29UV5ePmC8vLw82traBl2zd+/eePDBB6O3tze2bNkSt9xyS9x5553x7W9/+6jXaWxsjLKysv5bZWVlPtsEAMapEf9UUV9fX0ydOjXuueeemD17dixYsCBWrlwZ69evP+qaFStWREdHR/9t//79I71NACABeb05d8qUKVFUVBTt7e0Dxtvb26OiomLQNdOmTYsTTjghioqK+sc++MEPRltbW/T09ERxcfERa3K5XORyuXy2BgBMAHk941JcXByzZ8+O5ubm/rG+vr5obm6OmpqaQddceOGF8dxzz0VfX1//2LPPPhvTpk0bNFoAAI4m75eK6uvrY8OGDfGTn/wkdu/eHdddd110dXXFkiVLIiJi0aJFsWLFiv751113Xbzyyitxww03xLPPPhubN2+O1atXx9KlS4fvUQAAE0Le3+OyYMGCePnll2PVqlXR1tYWs2bNiq1bt/a/YXffvn1RWPjfHqqsrIxHHnkkli1bFueee27MmDEjbrjhhrjxxhuH71EAABNC3t/jMhZ8jwsApGfMv8cFAGAsCRcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIxpDCpampKaqqqqKkpCSqq6tj+/btx7Ru48aNUVBQEPPnzx/KZQGACS7vcNm0aVPU19dHQ0ND7Ny5M2bOnBl1dXXx0ksvvem6F198Mb72ta/FRRddNOTNAgATW97hctddd8XVV18dS5YsiQ996EOxfv36OOmkk+K+++476pre3t74whe+ELfeemucfvrpb3mN7u7u6OzsHHADAMgrXHp6emLHjh1RW1v73zsoLIza2tpoaWk56rpvfetbMXXq1LjyyiuP6TqNjY1RVlbWf6usrMxnmwDAOJVXuBw4cCB6e3ujvLx8wHh5eXm0tbUNuuaxxx6Le++9NzZs2HDM11mxYkV0dHT03/bv35/PNgGAcWrSSN75oUOHYuHChbFhw4aYMmXKMa/L5XKRy+VGcGcAQIryCpcpU6ZEUVFRtLe3Dxhvb2+PioqKI+Y///zz8eKLL8a8efP6x/r6+v5z4UmT4plnnokzzjhjKPsGACagvF4qKi4ujtmzZ0dzc3P/WF9fXzQ3N0dNTc0R888666x48skno7W1tf/26U9/Oi655JJobW313hUAIC95v1RUX18fixcvjjlz5sTcuXNj7dq10dXVFUuWLImIiEWLFsWMGTOisbExSkpK4uyzzx6w/tRTT42IOGIcAOCt5B0uCxYsiJdffjlWrVoVbW1tMWvWrNi6dWv/G3b37dsXhYW+kBcAGH4FWZZlY72Jt9LZ2RllZWXR0dERpaWlY70dAOAYjMTPb0+NAADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQjCGFS1NTU1RVVUVJSUlUV1fH9u3bjzp3w4YNcdFFF8XkyZNj8uTJUVtb+6bzAQCOJu9w2bRpU9TX10dDQ0Ps3LkzZs6cGXV1dfHSSy8NOn/btm1x+eWXx+9///toaWmJysrK+NSnPhV/+9vf3vbmAYCJpSDLsiyfBdXV1XH++efHunXrIiKir68vKisr4/rrr4/ly5e/5fre3t6YPHlyrFu3LhYtWjTonO7u7uju7u7/c2dnZ1RWVkZHR0eUlpbms10AYIx0dnZGWVnZsP78zusZl56entixY0fU1tb+9w4KC6O2tjZaWlqO6T5effXVeP311+Md73jHUec0NjZGWVlZ/62ysjKfbQIA41Re4XLgwIHo7e2N8vLyAePl5eXR1tZ2TPdx4403xvTp0wfEz/9asWJFdHR09N/279+fzzYBgHFq0mhebM2aNbFx48bYtm1blJSUHHVeLpeLXC43ijsDAFKQV7hMmTIlioqKor29fcB4e3t7VFRUvOnaO+64I9asWRO//e1v49xzz81/pwDAhJfXS0XFxcUxe/bsaG5u7h/r6+uL5ubmqKmpOeq622+/PW677bbYunVrzJkzZ+i7BQAmtLxfKqqvr4/FixfHnDlzYu7cubF27dro6uqKJUuWRETEokWLYsaMGdHY2BgREd/97ndj1apV8bOf/Syqqqr63wtz8sknx8knnzyMDwUAGO/yDpcFCxbEyy+/HKtWrYq2traYNWtWbN26tf8Nu/v27YvCwv8+kfPDH/4wenp64rOf/eyA+2loaIhvfvObb2/3AMCEkvf3uIyFkfgcOAAwssb8e1wAAMaScAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkDClcmpqaoqqqKkpKSqK6ujq2b9/+pvMfeOCBOOuss6KkpCTOOeec2LJly5A2CwBMbHmHy6ZNm6K+vj4aGhpi586dMXPmzKirq4uXXnpp0PmPP/54XH755XHllVfGrl27Yv78+TF//vx46qmn3vbmAYCJpSDLsiyfBdXV1XH++efHunXrIiKir68vKisr4/rrr4/ly5cfMX/BggXR1dUVv/71r/vHPvrRj8asWbNi/fr1g16ju7s7uru7+//c0dERp512Wuzfvz9KS0vz2S4AMEY6OzujsrIyDh48GGVlZcNyn5PymdzT0xM7duyIFStW9I8VFhZGbW1ttLS0DLqmpaUl6uvrB4zV1dXFL3/5y6Nep7GxMW699dYjxisrK/PZLgBwHPjHP/4xNuFy4MCB6O3tjfLy8gHj5eXlsWfPnkHXtLW1DTq/ra3tqNdZsWLFgNg5ePBgvOc974l9+/YN2wNnaN6oZ89+jT1ncfxwFscX53H8eOMVk3e84x3Ddp95hctoyeVykcvljhgvKyvzD+FxorS01FkcJ5zF8cNZHF+cx/GjsHD4PsSc1z1NmTIlioqKor29fcB4e3t7VFRUDLqmoqIir/kAAEeTV7gUFxfH7Nmzo7m5uX+sr68vmpubo6amZtA1NTU1A+ZHRDz66KNHnQ8AcDR5v1RUX18fixcvjjlz5sTcuXNj7dq10dXVFUuWLImIiEWLFsWMGTOisbExIiJuuOGGuPjii+POO++Myy67LDZu3BhPPPFE3HPPPcd8zVwuFw0NDYO+fMTochbHD2dx/HAWxxfncfwYibPI++PQERHr1q2L733ve9HW1hazZs2K73//+1FdXR0RER//+Mejqqoq7r///v75DzzwQNx8883x4osvxvvf//64/fbb49JLLx22BwEATAxDChcAgLHgdxUBAMkQLgBAMoQLAJAM4QIAJOO4CZempqaoqqqKkpKSqK6uju3bt7/p/AceeCDOOuusKCkpiXPOOSe2bNkySjsd//I5iw0bNsRFF10UkydPjsmTJ0dtbe1bnh3HLt+/F2/YuHFjFBQUxPz580d2gxNIvmdx8ODBWLp0aUybNi1yuVyceeaZ/j01TPI9i7Vr18YHPvCBOPHEE6OysjKWLVsWr7322ijtdvz6wx/+EPPmzYvp06dHQUHBm/4Owjds27YtPvKRj0Qul4v3ve99Az6BfMyy48DGjRuz4uLi7L777sv+/Oc/Z1dffXV26qmnZu3t7YPO/+Mf/5gVFRVlt99+e/b0009nN998c3bCCSdkTz755CjvfPzJ9yyuuOKKrKmpKdu1a1e2e/fu7Itf/GJWVlaW/fWvfx3lnY8/+Z7FG1544YVsxowZ2UUXXZR95jOfGZ3NjnP5nkV3d3c2Z86c7NJLL80ee+yx7IUXXsi2bduWtba2jvLOx598z+KnP/1plsvlsp/+9KfZCy+8kD3yyCPZtGnTsmXLlo3yzsefLVu2ZCtXrsweeuihLCKyhx9++E3n7927NzvppJOy+vr67Omnn85+8IMfZEVFRdnWrVvzuu5xES5z587Nli5d2v/n3t7ebPr06VljY+Og8z/3uc9ll1122YCx6urq7Etf+tKI7nMiyPcs/tfhw4ezU045JfvJT34yUlucMIZyFocPH84uuOCC7Ec/+lG2ePFi4TJM8j2LH/7wh9npp5+e9fT0jNYWJ4x8z2Lp0qXZJz7xiQFj9fX12YUXXjii+5xojiVcvvGNb2Qf/vCHB4wtWLAgq6ury+taY/5SUU9PT+zYsSNqa2v7xwoLC6O2tjZaWloGXdPS0jJgfkREXV3dUedzbIZyFv/r1Vdfjddff31YfxPoRDTUs/jWt74VU6dOjSuvvHI0tjkhDOUsfvWrX0VNTU0sXbo0ysvL4+yzz47Vq1dHb2/vaG17XBrKWVxwwQWxY8eO/peT9u7dG1u2bPElqGNguH52j/lvhz5w4ED09vZGeXn5gPHy8vLYs2fPoGva2toGnd/W1jZi+5wIhnIW/+vGG2+M6dOnH/EPJ/kZylk89thjce+990Zra+so7HDiGMpZ7N27N373u9/FF77whdiyZUs899xz8eUvfzlef/31aGhoGI1tj0tDOYsrrrgiDhw4EB/72Mciy7I4fPhwXHvttXHTTTeNxpb5f472s7uzszP+/e9/x4knnnhM9zPmz7gwfqxZsyY2btwYDz/8cJSUlIz1diaUQ4cOxcKFC2PDhg0xZcqUsd7OhNfX1xdTp06Ne+65J2bPnh0LFiyIlStXxvr168d6axPOtm3bYvXq1XH33XfHzp0746GHHorNmzfHbbfdNtZbY4jG/BmXKVOmRFFRUbS3tw8Yb29vj4qKikHXVFRU5DWfYzOUs3jDHXfcEWvWrInf/va3ce65547kNieEfM/i+eefjxdffDHmzZvXP9bX1xcREZMmTYpnnnkmzjjjjJHd9Dg1lL8X06ZNixNOOCGKior6xz74wQ9GW1tb9PT0RHFx8YjuebwaylnccsstsXDhwrjqqqsiIuKcc86Jrq6uuOaaa2LlypVRWOi/30fL0X52l5aWHvOzLRHHwTMuxcXFMXv27Ghubu4f6+vri+bm5qipqRl0TU1NzYD5ERGPPvroUedzbIZyFhERt99+e9x2222xdevWmDNnzmhsddzL9yzOOuusePLJJ6O1tbX/9ulPfzouueSSaG1tjcrKytHc/rgylL8XF154YTz33HP98RgR8eyzz8a0adNEy9swlLN49dVXj4iTN4Iy86v6RtWw/ezO733DI2Pjxo1ZLpfL7r///uzpp5/OrrnmmuzUU0/N2trasizLsoULF2bLly/vn//HP/4xmzRpUnbHHXdku3fvzhoaGnwcepjkexZr1qzJiouLswcffDD7+9//3n87dOjQWD2EcSPfs/hfPlU0fPI9i3379mWnnHJK9pWvfCV75plnsl//+tfZ1KlTs29/+9tj9RDGjXzPoqGhITvllFOyn//859nevXuz3/zmN9kZZ5yRfe5znxurhzBuHDp0KNu1a1e2a9euLCKyu+66K9u1a1f2l7/8JcuyLFu+fHm2cOHC/vlvfBz661//erZ79+6sqakp3Y9DZ1mW/eAHP8hOO+20rLi4OJs7d272pz/9qf9/u/jii7PFixcPmP+LX/wiO/PMM7Pi4uLswx/+cLZ58+ZR3vH4lc9ZvOc978ki4ohbQ0PD6G98HMr378X/J1yGV75n8fjjj2fV1dVZLpfLTj/99Ow73/lOdvjw4VHe9fiUz1m8/vrr2Te/+c3sjDPOyEpKSrLKysrsy1/+cvbPf/5z9Dc+zvz+978f9N//b/z/v3jx4uziiy8+Ys2sWbOy4uLi7PTTT89+/OMf533dgizzXBkAkIYxf48LAMCxEi4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJCM/wM9kKRvAVrZIAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([t/600 for t in train_correct],label='Training Accuracy')\n",
    "plt.plot([t/100 for t in test_correct], label='Validation Accuracy')\n",
    "plt.title('Accuracy at the end of the epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load_all  = DataLoader(test_data,batch_size=10000,shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "\n",
    "    for X_test,y_test in test_load_all:\n",
    "        y_val = model(X_test)\n",
    "        predicted = torch.max(y_val,1)[1]\n",
    "        correct += (predicted == y_test).sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.74000000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.item()/len(test_data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    2    3    4    5    6    7    8    9]]\n",
      "\n",
      "[[ 975    0    1    0    0    1    4    0    4    0]\n",
      " [   0 1127    1    1    1    0    2    3    0    0]\n",
      " [   1    0 1016    0    1    0    1    3    2    1]\n",
      " [   0    1    5 1004    0   10    0    2    4    5]\n",
      " [   0    0    1    0  970    0    1    0    2    1]\n",
      " [   0    1    0    2    0  877    4    0    2    4]\n",
      " [   1    4    0    0    3    2  945    0    1    0]\n",
      " [   1    2    8    2    1    0    0 1013    1    3]\n",
      " [   0    0    0    1    0    0    1    1  953    1]\n",
      " [   2    0    0    0    6    2    0    6    5  994]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.com/api/asset/download?assetId=2d16660009624ffd94cf4f54e294b934&experimentKey=9747c053e21b45aca0f00ea13f1965d5',\n",
       " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=2d16660009624ffd94cf4f54e294b934&experimentKey=9747c053e21b45aca0f00ea13f1965d5',\n",
       " 'assetId': '2d16660009624ffd94cf4f54e294b934'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a row of values for reference\n",
    "np.set_printoptions(formatter=dict(int=lambda x: f'{x:4}'))\n",
    "print(np.arange(10).reshape(1,10))\n",
    "print()\n",
    "\n",
    "# print the confusion matrix\n",
    "confusion_mat = confusion_matrix(predicted.view(-1), y_test.view(-1))\n",
    "\n",
    "print(confusion_mat)\n",
    "\n",
    "\n",
    "experiment.log_confusion_matrix(matrix=confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number in the image is : 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chosen_index = int(input(\"Choose a number between 1 to 10,000: \"))\n",
    "plt.imshow(test_data[chosen_index][0].reshape(28,28))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_pred = model(test_data[chosen_index][0].view(1,1,28,28))\n",
    "print(f\"The number in the image is : {new_pred.argmax().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/wereign/juan-ai/1f5f9c8969024f81947e2e2cb897cf5a\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [4302]            : (3.576278473360617e-08, 2.337458610534668)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_accuracy [43020] : (0.0, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss [43020]     : (0.0, 2.375399589538574)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_accuracy [7]       : (0.9861861861861861, 9801)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val_loss [7]           : (2.312652895852807e-06, 0.03071148693561554)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs        : 30\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss          : categorical_crossentropy\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer     : Adam\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (162.41 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element                : 2 (238.05 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49b76041c373911fded19fce7465faa07019cc579c640fc8bbed67f9fbbaffdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
